{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "94245c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.datasets import SST2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import GloVe\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2b6f2ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2ccf8dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up tokenization\n",
    "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "85b1560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GloVe embedded vectors\n",
    "glove = GloVe(name='6B', dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "837d394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing and padding functions\n",
    "def text_pipeline(text):\n",
    "    if isinstance(text, str):\n",
    "        return [glove.stoi[token] if token in glove.stoi else 0 for token in tokenizer(text)]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0ff55371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "train_iter = SST2(split='train')\n",
    "valid_iter = SST2(split='dev')\n",
    "test_iter = SST2(split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3dd6f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing function\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, length_list = [], [], []\n",
    "    \n",
    "    # Uncomment the following line to print the entire batch content for debugging\n",
    "    # print(f\"Batch content: {batch}\")\n",
    "    \n",
    "    for data in batch:\n",
    "        if len(data) != 2:\n",
    "            # Print unexpected data formats (optional)\n",
    "            # print(f\"Unexpected batch format: {data}\")\n",
    "            continue\n",
    "        \n",
    "        _label, _text = data\n",
    "        \n",
    "        processed_text = text_pipeline(_text)\n",
    "        if len(processed_text) == 0:\n",
    "            continue\n",
    "        \n",
    "        label = torch.tensor(1.0 if _label == '1' else 0.0)  # Binary classification label\n",
    "        processed_text = torch.tensor(processed_text).long()  # Convert to LongTensor\n",
    "        \n",
    "        # Optional: limit the amount of debugging output\n",
    "        # print(f\"Processed text (length): {len(processed_text)}, Label: {label}\")\n",
    "\n",
    "        label_list.append(label)\n",
    "        text_list.append(processed_text)\n",
    "        length_list.append(len(processed_text))\n",
    "\n",
    "    if len(text_list) == 0:\n",
    "        return None, None, None\n",
    "\n",
    "    text_list = pad_sequence(text_list, batch_first=True)\n",
    "    label_list = torch.tensor(label_list, dtype=torch.float32)\n",
    "    length_list = torch.tensor(length_list)\n",
    "\n",
    "    return text_list.to(device), label_list.to(device), length_list.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "010fad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure data loader\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(list(train_iter), batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "valid_loader = DataLoader(list(valid_iter), batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "test_loader = DataLoader(list(test_iter), batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cf18f0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model definition\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, output_dim, num_layers, dropout):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(glove.vectors)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, \n",
    "                            bidirectional=True, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # Bidirectional LSTM, so 2x\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, text, text_lengths):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e6558884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters for the model\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1  # Binary classification (positive or negative)\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "83636119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = LSTMClassifier(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4a3d50fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "85f1b87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training functions\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        if batch is None:\n",
    "            continue\n",
    "        text, labels, text_lengths = batch\n",
    "        if text is None:\n",
    "            continue\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        \n",
    "        # Optional: limit the amount of output per batch\n",
    "        if i % 10 == 0:  # Print only every 10th batch\n",
    "            print(f\"Batch {i}: Predictions shape: {predictions.shape}\")\n",
    "\n",
    "        loss = criterion(predictions, labels)\n",
    "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "        correct = (rounded_preds == labels).float()\n",
    "        acc = correct.sum() / len(correct)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "976a102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for evaluation\n",
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            if batch is None:\n",
    "                continue\n",
    "            text, labels, text_lengths = batch\n",
    "            if text is None:\n",
    "                continue\n",
    "            \n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            \n",
    "            # Optional: limit the amount of output per batch\n",
    "            if i % 10 == 0:  # Print only every 10th batch\n",
    "                print(f\"Eval Batch {i}: Predictions shape: {predictions.shape}\")\n",
    "            \n",
    "            loss = criterion(predictions, labels)\n",
    "            rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "            correct = (rounded_preds == labels).float()\n",
    "            acc = correct.sum() / len(correct)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "eb148c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "\tTrain Loss: 0.000 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.000 |  Val. Acc: 0.00%\n",
      "Epoch: 2\n",
      "\tTrain Loss: 0.000 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.000 |  Val. Acc: 0.00%\n",
      "Epoch: 3\n",
      "\tTrain Loss: 0.000 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.000 |  Val. Acc: 0.00%\n",
      "Epoch: 4\n",
      "\tTrain Loss: 0.000 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.000 |  Val. Acc: 0.00%\n",
      "Epoch: 5\n",
      "\tTrain Loss: 0.000 | Train Acc: 0.00%\n",
      "\t Val. Loss: 0.000 |  Val. Acc: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Perform training and evaluation\n",
    "N_EPOCHS = 5\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_loader, criterion)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2458a2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.000 | Test Acc: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test data\n",
    "test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a232bec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
